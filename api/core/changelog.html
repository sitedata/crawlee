<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page api-version-current plugin-typedoc-api plugin-id-default">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-rc.1">
<link rel="search" type="application/opensearchdescription+xml" title="Crawlee" href="/opensearch.xml">


<script src="/js/custom.js"></script><title data-rh="true">Changelog | API | Crawlee</title><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://crawlee.dev/img/apify_og_SDK.png"><meta data-rh="true" name="twitter:image" content="https://crawlee.dev/img/apify_og_SDK.png"><meta data-rh="true" property="og:url" content="https://crawlee.dev/api/core/changelog"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Changelog | API | Crawlee"><meta data-rh="true" name="description" content="Change Log"><meta data-rh="true" property="og:description" content="Change Log"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://crawlee.dev/api/core/changelog"><link data-rh="true" rel="alternate" href="https://crawlee.dev/api/core/changelog" hreflang="en"><link data-rh="true" rel="alternate" href="https://crawlee.dev/api/core/changelog" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://5JC94MPMLY-dsn.algolia.net" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.91c681c5.css">
<link rel="preload" href="/assets/js/runtime~main.9bda2722.js" as="script">
<link rel="preload" href="/assets/js/main.3e40fcfa.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function e(e){document.documentElement.setAttribute("data-theme",e)}var t=function(){var e=null;try{e=localStorage.getItem("theme")}catch(e){}return e}();null!==t?e(t):window.matchMedia("(prefers-color-scheme: dark)").matches?e("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,e("light"))}()</script><div id="__docusaurus">
<div class="apiPage"><div role="region"><a href="#" class="skipToContent_fXgn">Skip to main content</a></div><nav class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/crawlee-light.svg" alt="" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/crawlee-dark.svg" alt="" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Crawlee</b></a><a class="navbar__item navbar__link" href="/docs/quick-start">Docs</a><a class="navbar__item navbar__link" href="/docs/examples">Examples</a><a class="navbar__item navbar__link" href="/api/core">API reference</a><a aria-current="page" class="navbar__item navbar__link changelog navbar__link--active" href="/api/core/changelog">Changelog</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a class="navbar__link" aria-haspopup="true" aria-expanded="false" role="button" href="/docs/quick-start">3.0.0</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/docs/quick-start">3.0.0</a></li><li><a href="https://sdk.apify.com/docs/guides/getting-started" target="_blank" rel="noopener noreferrer" class="dropdown__link">2.2<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://sdk.apify.com/docs/1.3.1/guides/getting-started" target="_blank" rel="noopener noreferrer" class="dropdown__link">1.3<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><a href="https://github.com/apify/crawlee" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link icon" title="View on GitHub">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://discord.com/invite/jyEM2PRvMU" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link icon" title="Chat on Discord">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebar_njMd sidebarWithHideableNavbar_wUlq"><a tabindex="-1" class="sidebarLogo_isFc" href="/"><img src="/img/crawlee-light.svg" alt="" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/crawlee-dark.svg" alt="" class="themedImage_ToTc themedImage--dark_i4oU"><b>Crawlee</b></a><nav class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/api/basic-crawler">@crawlee/basic</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/api/browser-crawler">@crawlee/browser</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/api/browser-pool">@crawlee/browser-pool</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/api/cheerio-crawler">@crawlee/cheerio</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/api/core">@crawlee/core</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/api/core">Overview</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/api/core/class/AutoscaledPool">Classes</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/api/core/enum/EnqueueStrategy">Enumerations</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/api/core/function/enqueueLinks">Functions</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/api/core/interface/AutoscaledPoolOptions">Interfaces</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/api/core#EventTypeName">Type Aliases</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/api/core#log">Variables</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/api/core/changelog">Changelog</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/api/memory-storage">@crawlee/memory-storage</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/api/playwright-crawler">@crawlee/playwright</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/api/puppeteer-crawler">@crawlee/puppeteer</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/api/types">@crawlee/types</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/api/utils">@crawlee/utils</a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col apiItemCol"><div class="apiItemContainer"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_OVgt"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">@crawlee/core</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Changelog</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile apiTocMobile"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Changelog</h1></header><section class="tsd-readme"><h1 id="change-log">Change Log</h1><p>All notable changes to this project will be documented in this file.
See <a href="https://conventionalcommits.org">Conventional Commits</a> for commit guidelines.</p><h2 id="300-2022-07-13"><a href="https://github.com/apify/crawlee/compare/v2.3.2...v3.0.0">3.0.0</a> (2022-07-13)</h2><p>This section summarizes most of the breaking changes between Crawlee (v3) and Apify SDK (v2). Crawlee is the spiritual successor to Apify SDK, so we decided to keep the versioning and release Crawlee as v3.</p><h3 id="crawlee-vs-apify-sdk">Crawlee vs Apify SDK</h3><p>Up until version 3 of <code>apify</code>, the package contained both scraping related tools and Apify platform related helper methods. With v3 we are splitting the whole project into two main parts:</p><ul><li>Crawlee, the new web-scraping library, available as <code>crawlee</code> package on NPM</li><li>Apify SDK, helpers for the Apify platform, available as <code>apify</code> package on NPM</li></ul><p>Moreover, the Crawlee library is published as several packages under <code>@crawlee</code> namespace:</p><ul><li><code>@crawlee/core</code>: the base for all the crawler implementations, also contains things like <code>Request</code>, <code>RequestQueue</code>, <code>RequestList</code> or <code>Dataset</code> classes</li><li><code>@crawlee/basic</code>: exports <code>BasicCrawler</code></li><li><code>@crawlee/cheerio</code>: exports <code>CheerioCrawler</code></li><li><code>@crawlee/browser</code>: exports <code>BrowserCrawler</code> (which is used for creating <code>@crawlee/playwright</code> and <code>@crawlee/puppeteer</code>)</li><li><code>@crawlee/playwright</code>: exports <code>PlaywrightCrawler</code></li><li><code>@crawlee/puppeteer</code>: exports <code>PuppeteerCrawler</code></li><li><code>@crawlee/memory-storage</code>: <code>@apify/storage-local</code> alternative</li><li><code>@crawlee/browser-pool</code>: previously <code>browser-pool</code> package</li><li><code>@crawlee/utils</code>: utility methods</li><li><code>@crawlee/types</code>: holds TS interfaces mainly about the <code>StorageClient</code></li></ul><h4 id="installing-crawlee">Installing Crawlee</h4><blockquote><p>As Crawlee is not yet released as <code>latest</code>, we need to install from the <code>next</code> distribution tag!</p></blockquote><p>Most of the Crawlee packages are extending and reexporting each other, so it&#x27;s enough to install just the one you plan on using, e.g. <code>@crawlee/playwright</code> if you plan on using <code>playwright</code> - it already contains everything from the <code>@crawlee/browser</code> package, which includes everything from <code>@crawlee/basic</code>, which includes everything from <code>@crawlee/core</code>.</p><pre><code class="language-bash">npm install crawlee@next
</code></pre><p>Or if all we need is cheerio support, we can install only @crawlee/cheerio</p><pre><code class="language-bash">npm install @crawlee/cheerio@next
</code></pre><p>When using <code>playwright</code> or <code>puppeteer</code>, we still need to install those dependencies explicitly - this allows the users to be in control of which version will be used.</p><pre><code class="language-bash">npm install crawlee@next playwright
# or npm install @crawlee/playwright@next playwright
</code></pre><p>Alternatively we can also use the <code>crawlee</code> meta-package which contains (re-exports) most of the <code>@crawlee/*</code> packages, and therefore contains all the crawler classes.</p><blockquote><p>Sometimes you might want to use some utility methods from <code>@crawlee/utils</code>, so you might want to install that as well. This package contains some utilities that were previously available under <code>Apify.utils</code>. Browser related utilities can be also found in the crawler packages (e.g. <code>@crawlee/playwright</code>).</p></blockquote><h3 id="full-typescript-support">Full TypeScript support</h3><p>Both Crawlee and Apify SDK are full TypeScript rewrite, so they include up-to-date types in the package. For your TypeScript crawlers we recommend using our predefined TypeScript configuration from <code>@apify/tsconfig</code> package. Don&#x27;t forget to set the <code>module</code> and <code>target</code> to <code>ES2022</code> or above to be able to use top level await.</p><blockquote><p>The <code>@apify/tsconfig</code> config has <a href="https://www.typescriptlang.org/tsconfig#noImplicitAny"><code>noImplicitAny</code></a> enabled, you might want to disable it during the initial development as it will cause build failures if you left some unused local variables in your code.</p></blockquote><pre><code class="language-json" metastring="title=&quot;tsconfig.json&quot;" title="&quot;tsconfig.json&quot;">{
    &quot;extends&quot;: &quot;@apify/tsconfig&quot;,
    &quot;compilerOptions&quot;: {
        &quot;module&quot;: &quot;ES2022&quot;,
        &quot;target&quot;: &quot;ES2022&quot;,
        &quot;outDir&quot;: &quot;dist&quot;,
        &quot;lib&quot;: [&quot;DOM&quot;]
    },
    &quot;include&quot;: [
        &quot;./src/**/*&quot;
    ]
}
</code></pre><h4 id="docker-build">Docker build</h4><p>For <code>Dockerfile</code> we recommend using multi-stage build, so you don&#x27;t install the dev dependencies like TypeScript in your final image:</p><pre><code class="language-dockerfile" metastring="title=&quot;Dockerfile&quot;" title="&quot;Dockerfile&quot;"># using multistage build, as we need dev deps to build the TS source code
FROM apify/actor-node:16 AS builder

# copy all files, install all dependencies (including dev deps) and build the project
COPY . ./
RUN npm install --include=dev \
    &amp;&amp; npm run build

# create final image
FROM apify/actor-node:16
# copy only necessary files
COPY --from=builder /usr/src/app/package*.json ./
COPY --from=builder /usr/src/app/README.md ./
COPY --from=builder /usr/src/app/dist ./dist
COPY --from=builder /usr/src/app/apify.json ./apify.json
COPY --from=builder /usr/src/app/INPUT_SCHEMA.json ./INPUT_SCHEMA.json

# install only prod deps
RUN npm --quiet set progress=false \
    &amp;&amp; npm install --only=prod --no-optional \
    &amp;&amp; echo &quot;Installed NPM packages:&quot; \
    &amp;&amp; (npm list --only=prod --no-optional --all || true) \
    &amp;&amp; echo &quot;Node.js version:&quot; \
    &amp;&amp; node --version \
    &amp;&amp; echo &quot;NPM version:&quot; \
    &amp;&amp; npm --version

# run compiled code
CMD npm run start:prod
</code></pre><h3 id="browser-fingerprints">Browser fingerprints</h3><p>Previously we had a magical <code>stealth</code> option in the puppeteer crawler that enabled several tricks aiming to mimic the real users as much as possible. While this worked to a certain degree, we decided to replace it with generated browser fingerprints.</p><p>In case we don&#x27;t want to have dynamic fingerprints, we can disable this behaviour via <code>useFingerprints</code> in <code>browserPoolOptions</code>:</p><pre><code class="language-ts">const crawler = new PlaywrightCrawler({
   browserPoolOptions: {
       useFingerprints: false,
   },
});
</code></pre><h3 id="session-cookie-method-renames">Session cookie method renames</h3><p>Previously, if we wanted to get or add cookies for the session that would be used for the request, we had to call <code>session.getPuppeteerCookies()</code> or <code>session.setPuppeteerCookies()</code>. Since this method could be used for any of our crawlers, not just <code>PuppeteerCrawler</code>, the methods have been renamed to <code>session.getCookies()</code> and <code>session.setCookies()</code> respectively. Otherwise, their usage is exactly the same!</p><h3 id="memory-storage">Memory storage</h3><p>When we store some data or intermediate state (like the one <code>RequestQueue</code> holds), we now use <code>@crawlee/memory-storage</code> by default. It is an alternative to the <code>@apify/storage-local</code>, that stores the state inside memory (as opposed to SQLite database used by <code>@apify/storage-local</code>). While the state is stored in memory, it also dumps it to the file system, so we can observe it, as well as respects the existing data stored in KeyValueStore (e.g. the <code>INPUT.json</code> file).</p><p>When we want to run the crawler on Apify platform, we need to use <code>Actor.init</code> or <code>Actor.main</code>, which will automatically switch the storage client to <code>ApifyClient</code> when on the Apify platform.</p><p>We can still use the <code>@apify/storage-local</code>, to do it, first install it pass it to the <code>Actor.init</code> or <code>Actor.main</code> options:</p><blockquote><p><code>@apify/storage-local</code> v2.1.0+ is required for Crawlee</p></blockquote><pre><code class="language-ts">import { Actor } from &#x27;apify&#x27;;
import { ApifyStorageLocal } from &#x27;@apify/storage-local&#x27;;

const storage = new ApifyStorageLocal(/* options like `enableWalMode` belong here */);
await Actor.init({ storage });
</code></pre><h3 id="purging-of-the-default-storage">Purging of the default storage</h3><p>Previously the state was preserved between local runs, and we had to use <code>--purge</code> argument of the <code>apify-cli</code>. With Crawlee, this is now the default behaviour, we purge the storage automatically on <code>Actor.init/main</code> call. We can opt out of it via <code>purge: false</code> in the <code>Actor.init</code> options.</p><h3 id="renamed-crawler-options-and-interfaces">Renamed crawler options and interfaces</h3><p>Some options were renamed to better reflect what they do. We still support all the old parameter names too, but not at the TS level.</p><ul><li><code>handleRequestFunction</code> -&gt; <code>requestHandler</code></li><li><code>handlePageFunction</code> -&gt; <code>requestHandler</code></li><li><code>handleRequestTimeoutSecs</code> -&gt; <code>requestHandlerTimeoutSecs</code></li><li><code>handlePageTimeoutSecs</code> -&gt; <code>requestHandlerTimeoutSecs</code></li><li><code>requestTimeoutSecs</code> -&gt; <code>navigationTimeoutSecs</code></li><li><code>handleFailedRequestFunction</code> -&gt; <code>failedRequestHandler</code></li></ul><p>We also renamed the crawling context interfaces, so they follow the same convention and are more meaningful:</p><ul><li><code>CheerioHandlePageInputs</code> -&gt; <code>CheerioCrawlingContext</code></li><li><code>PlaywrightHandlePageFunction</code> -&gt; <code>PlaywrightCrawlingContext</code></li><li><code>PuppeteerHandlePageFunction</code> -&gt; <code>PuppeteerCrawlingContext</code></li></ul><h3 id="context-aware-helpers">Context aware helpers</h3><p>Some utilities previously available under <code>Apify.utils</code> namespace are now moved to the crawling context and are <em>context aware</em>. This means they have some parameters automatically filled in from the context, like the current <code>Request</code> instance or current <code>Page</code> object, or the <code>RequestQueue</code> bound to the crawler.</p><h4 id="enqueuing-links">Enqueuing links</h4><p>One common helper that received more attention is the <code>enqueueLinks</code>. As mentioned above, it is context aware - we no longer need pass in the <code>requestQueue</code> or <code>page</code> arguments (or the cheerio handle <code>$</code>). In addition to that, it now offers 3 enqueuing strategies:</p><ul><li><code>EnqueueStrategy.All</code> (<code>&#x27;all&#x27;</code>): Matches any URLs found</li><li><code>EnqueueStrategy.SameHostname</code> (<code>&#x27;same-hostname&#x27;</code>) Matches any URLs that have the same subdomain as the base URL (default)</li><li><code>EnqueueStrategy.SameDomain</code> (<code>&#x27;same-domain&#x27;</code>) Matches any URLs that have the same domain name. For example, <code>https://wow.an.example.com</code> and <code>https://example.com</code> will both be matched for a base url of <code>https://example.com</code>.</li></ul><p>This means we can even call <code>enqueueLinks()</code> without any parameters. By default, it will go through all the links found on current page and filter only those targeting the same subdomain.</p><p>Moreover, we can specify patterns the URL should match via globs:</p><pre><code class="language-ts">const crawler = new PlaywrightCrawler({
    async requestHandler({ enqueueLinks }) {
        await enqueueLinks({
            globs: [&#x27;https://apify.com/*/*&#x27;],
            // we can also use `regexps` and `pseudoUrls` keys here
        });
    },
});
</code></pre><h3 id="implicit-requestqueue-instance">Implicit <code>RequestQueue</code> instance</h3><p>All crawlers now have the <code>RequestQueue</code> instance automatically available via <code>crawler.getRequestQueue()</code> method. It will create the instance for you if it does not exist yet. This mean we no longer need to create the <code>RequestQueue</code> instance manually, and we can just use <code>crawler.addRequests()</code> method described underneath.</p><blockquote><p>We can still create the <code>RequestQueue</code> explicitly, the <code>crawler.getRequestQueue()</code> method will respect that and return the instance provided via crawler options.</p></blockquote><h3 id="crawleraddrequests"><code>crawler.addRequests()</code></h3><p>We can now add multiple requests in batches. The newly added <code>addRequests</code> method will handle everything for us. It enqueues the first 1000 requests and resolves, while continuing with the rest in the background, again in a smaller 1000 items batches, so we don&#x27;t fall into any API rate limits. This means the crawling will start almost immediately (within few seconds at most), something previously possible only with a combination of <code>RequestQueue</code> and <code>RequestList</code>.</p><pre><code class="language-ts">// will resolve right after the initial batch of 1000 requests is added
const result = await crawler.addRequests([/* many requests, can be even millions */]);

// if we want to wait for all the requests to be added, we can await the `waitForAllRequestsToBeAdded` promise
await result.waitForAllRequestsToBeAdded;
</code></pre><h3 id="less-verbose-error-logging">Less verbose error logging</h3><p>Previously an error thrown from inside request handler resulted in full error object being logged. With Crawlee, we log only the error message as a warning as long as we know the request will be retried. If you want to enable verbose logging like in v2, use the <code>CRAWLEE_VERBOSE_LOG</code> env var.</p><h3 id="removal-of-requestasbrowser">Removal of <code>requestAsBrowser</code></h3><p>In v1 we replaced the underlying implementation of <code>requestAsBrowser</code> to be just a proxy over calling <a href="https://github.com/apify/got-scraping"><code>got-scraping</code></a> - our custom extension to <code>got</code> that tries to mimic the real browsers as much as possible. With v3, we are removing the <code>requestAsBrowser</code>, encouraging the use of <a href="https://github.com/apify/got-scraping"><code>got-scraping</code></a> directly.</p><p>For easier migration, we also added <code>context.sendRequest()</code> helper that allows processing the context bound <code>Request</code> object through <a href="https://github.com/apify/got-scraping"><code>got-scraping</code></a>:</p><pre><code class="language-ts">const crawler = new BasicCrawler({
    async requestHandler({ sendRequest, log }) {
        // we can use the options parameter to override gotScraping options
        const res = await sendRequest({ responseType: &#x27;json&#x27; });
        log.info(&#x27;received body&#x27;, res.body);
    },
});
</code></pre><h4 id="how-to-use-sendrequest">How to use <code>sendRequest()</code>?</h4><p>See <a href="../guides/got_scraping.mdx">the Got Scraping guide</a>.</p><h4 id="removed-options">Removed options</h4><p>The <code>useInsecureHttpParser</code> option has been removed. It&#x27;s permanently set to <code>true</code> in order to better mimic browsers&#x27; behavior.</p><p>Got Scraping automatically performs protocol negotiation, hence we removed the <code>useHttp2</code> option. It&#x27;s set to <code>true</code> - 100% of browsers nowadays are capable of HTTP/2 requests. Oh, more and more of the web is using it too!</p><h4 id="renamed-options">Renamed options</h4><p>In the <code>requestAsBrowser</code> approach, some of the options were named differently. Here&#x27;s a list of renamed options:</p><h5 id="payload"><code>payload</code></h5><p>This options represents the body to send. It could be a <code>string</code> or a <code>Buffer</code>. However, there is no <code>payload</code> option anymore. You need to use <code>body</code> instead. Or, if you wish to send JSON, <code>json</code>. Here&#x27;s an example:</p><pre><code class="language-ts">// Before:
await Apify.utils.requestAsBrowser({ …, payload: &#x27;Hello, world!&#x27; });
await Apify.utils.requestAsBrowser({ …, payload: Buffer.from(&#x27;c0ffe&#x27;, &#x27;hex&#x27;) });
await Apify.utils.requestAsBrowser({ …, json: { hello: &#x27;world&#x27; } });

// After:
await gotScraping({ …, body: &#x27;Hello, world!&#x27; });
await gotScraping({ …, body: Buffer.from(&#x27;c0ffe&#x27;, &#x27;hex&#x27;) });
await gotScraping({ …, json: { hello: &#x27;world&#x27; } });
</code></pre><h5 id="ignoresslerrors"><code>ignoreSslErrors</code></h5><p>It has been renamed to <code>https.rejectUnauthorized</code>. By default, it&#x27;s set to <code>false</code> for convenience. However, if you want to make sure the connection is secure, you can do the following:</p><pre><code class="language-ts">// Before:
await Apify.utils.requestAsBrowser({ …, ignoreSslErrors: false });

// After:
await gotScraping({ …, https: { rejectUnauthorized: true } });
</code></pre><p>Please note: the meanings are opposite! So we needed to invert the values as well.</p><h5 id="header-generator-options"><code>header-generator</code> options</h5><p><code>useMobileVersion</code>, <code>languageCode</code> and <code>countryCode</code> no longer exist. Instead, you need to use <code>headerGeneratorOptions</code> directly:</p><pre><code class="language-ts">// Before:
await Apify.utils.requestAsBrowser({
    …,
    useMobileVersion: true,
    languageCode: &#x27;en&#x27;,
    countryCode: &#x27;US&#x27;,
});

// After:
await gotScraping({
    …,
    headerGeneratorOptions: {
        devices: [&#x27;mobile&#x27;], // or [&#x27;desktop&#x27;]
        locales: [&#x27;en-US&#x27;],
    },
});
</code></pre><h5 id="timeoutsecs"><code>timeoutSecs</code></h5><p>In order to set a timeout, use <code>timeout.request</code> (which is <strong>milliseconds</strong> now).</p><pre><code class="language-ts">// Before:
await Apify.utils.requestAsBrowser({
    …,
    timeoutSecs: 30,
});

// After:
await gotScraping({
    …,
    timeout: {
        request: 30 * 1000,
    },
});
</code></pre><h5 id="throwonhttperrors"><code>throwOnHttpErrors</code></h5><p><code>throwOnHttpErrors</code> → <code>throwHttpErrors</code>. This options throws on unsuccessful HTTP status codes, for example <code>404</code>. By default, it&#x27;s set to <code>false</code>.</p><h5 id="decodebody"><code>decodeBody</code></h5><p><code>decodeBody</code> → <code>decompress</code>. This options decompresses the body. Defaults to <code>true</code> - please do not change this or websites will break (unless you know what you&#x27;re doing!).</p><h5 id="abortfunction"><code>abortFunction</code></h5><p>This function used to make the promise throw on specific responses, if it returned <code>true</code>. However, it wasn&#x27;t that useful.</p><p>You probably want to cancel the request instead, which you can do in the following way:</p><pre><code class="language-ts">const promise = gotScraping(…);

promise.on(&#x27;request&#x27;, request =&gt; {
    // Please note this is not a Got Request instance, but a ClientRequest one.
    // https://nodejs.org/api/http.html#class-httpclientrequest

    if (request.protocol !== &#x27;https:&#x27;) {
        // Unsecure request, abort.
        promise.cancel();

        // If you set `isStream` to `true`, please use `stream.destroy()` instead.
    }
});

const response = await promise;
</code></pre><h3 id="removal-of-browser-pool-plugin-mixing">Removal of browser pool plugin mixing</h3><p>Previously, you were able to have a browser pool that would mix Puppeteer and Playwright plugins (or even your own custom plugins if you&#x27;ve built any). As of this version, that is no longer allowed, and creating such a browser pool will cause an error to be thrown (it&#x27;s expected that all plugins that will be used are of the same type).</p><admonition title="Confused?" type="info"><p>As an example, this change disallows a pool to mix Puppeteer with Playwright. You can still create pools that use multiple Playwright plugins, each with a different launcher if you want!</p></admonition><h3 id="handling-requests-outside-of-browser">Handling requests outside of browser</h3><p>One small feature worth mentioning is the ability to handle requests with browser crawlers outside the browser. To do that, we can use a combination of <code>Request.skipNavigation</code> and <code>context.sendRequest()</code>.</p><p>Take a look at how to achieve this by checking out the <a href="../examples/skip-navigation">Skipping navigation for certain requests</a> example!</p><h3 id="logging">Logging</h3><p>Crawlee exports the default <code>log</code> instance directly as a named export. We also have a scoped <code>log</code> instance provided in the crawling context - this one will log messages prefixed with the crawler name and should be preferred for logging inside the request handler.</p><pre><code class="language-ts">const crawler = new CheerioCrawler({
    async requestHandler({ log, request }) {
        log.info(`Opened ${request.loadedUrl}`);
    },
});
</code></pre><h3 id="auto-saved-crawler-state">Auto-saved crawler state</h3><p>Every crawler instance now has <code>useState()</code> method that will return a state object we can use. It will be automatically saved when <code>persistState</code> event occurs. The value is cached, so we can freely call this method multiple times and get the exact same reference. No need to worry about saving the value either, as it will happen automatically.</p><pre><code class="language-ts">const crawler = new CheerioCrawler({
    async requestHandler({ crawler }) {
        const state = await crawler.useState({ foo: [] as number[] });
        // just change the value, no need to care about saving it
        state.foo.push(123);
    },
});
</code></pre><h3 id="apify-sdk">Apify SDK</h3><p>The Apify platform helpers can be now found in the Apify SDK (<code>apify</code> NPM package). It exports the <code>Actor</code> class that offers following static helpers:</p><ul><li><code>ApifyClient</code> shortcuts: <code>addWebhook()</code>, <code>call()</code>, <code>callTask()</code>, <code>metamorph()</code></li><li>helpers for running on Apify platform: <code>init()</code>, <code>exit()</code>, <code>fail()</code>, <code>main()</code>, <code>isAtHome()</code>, <code>createProxyConfiguration()</code></li><li>storage support: <code>getInput()</code>, <code>getValue()</code>, <code>openDataset()</code>, <code>openKeyValueStore()</code>, <code>openRequestQueue()</code>, <code>pushData()</code>, <code>setValue()</code></li><li>events support: <code>on()</code>, <code>off()</code></li><li>other utilities: <code>getEnv()</code>, <code>newClient()</code>, <code>reboot()</code></li></ul><p><code>Actor.main</code> is now just a syntax sugar around calling <code>Actor.init()</code> at the beginning and <code>Actor.exit()</code> at the end (plus wrapping the user function in try/catch block). All those methods are async and should be awaited - with node 16 we can use the top level await for that. In other words, following is equivalent:</p><pre><code class="language-ts">import { Actor } from &#x27;apify&#x27;;

await Actor.init();
// your code
await Actor.exit(&#x27;Crawling finished!&#x27;);
</code></pre><pre><code class="language-ts">import { Actor } from &#x27;apify&#x27;;

await Actor.main(async () =&gt; {
    // your code
}, { statusMessage: &#x27;Crawling finished!&#x27; });
</code></pre><p><code>Actor.init()</code> will conditionally set the storage implementation of Crawlee to the <code>ApifyClient</code> when running on the Apify platform, or keep the default (memory storage) implementation otherwise. It will also subscribe to the websocket events (or mimic them locally). <code>Actor.exit()</code> will handle the tear down and calls <code>process.exit()</code> to ensure our process won&#x27;t hang indefinitely for some reason.</p><h4 id="events">Events</h4><p>Apify SDK (v2) exports <code>Apify.events</code>, which is an <code>EventEmitter</code> instance. With Crawlee, the events are managed by </p><div to="core/class/EventManager"><code>EventManager</code></div> class instead. We can either access it via <code>Actor.eventManager</code> getter, or use <code>Actor.on</code> and <code>Actor.off</code> shortcuts instead.<p></p><pre><code class="language-diff">-Apify.events.on(...);
+Actor.on(...);
</code></pre><blockquote><p>We can also get the </p><div to="core/class/EventManager"><code>EventManager</code></div> instance via <code>Configuration.getEventManager()</code>.<p></p></blockquote><p>In addition to the existing events, we now have an <code>exit</code> event fired when calling <code>Actor.exit()</code> (which is called at the end of <code>Actor.main()</code>). This event allows you to gracefully shut down any resources when <code>Actor.exit</code> is called.</p><h3 id="smallerinternal-breaking-changes">Smaller/internal breaking changes</h3><ul><li><code>Apify.call()</code> is now just a shortcut for running <code>ApifyClient.actor(actorId).call(input, options)</code>, while also taking the token inside env vars into account</li><li><code>Apify.callTask()</code> is now just a shortcut for running <code>ApifyClient.task(taskId).call(input, options)</code>, while also taking the token inside env vars into account</li><li><code>Apify.metamorph()</code> is now just a shortcut for running <code>ApifyClient.task(taskId).metamorph(input, options)</code>, while also taking the ACTOR_RUN_ID inside env vars into account</li><li><code>Apify.waitForRunToFinish()</code> has been removed, use <code>ApifyClient.waitForFinish()</code> instead</li><li><code>Actor.main/init</code> purges the storage by default</li><li>remove <code>purgeLocalStorage</code> helper, move purging to the storage class directly<ul><li><code>StorageClient</code> interface now has optional <code>purge</code> method</li><li>purging happens automatically via <code>Actor.init()</code> (you can opt out via <code>purge: false</code> in the options of <code>init/main</code> methods)</li></ul></li><li><code>QueueOperationInfo.request</code> is no longer available</li><li><code>Request.handledAt</code> is now string date in ISO format</li><li><code>Request.inProgress</code> and <code>Request.reclaimed</code> are now <code>Set</code>s instead of POJOs</li><li><code>injectUnderscore</code> from puppeteer utils has been removed</li><li><code>APIFY_MEMORY_MBYTES</code> is no longer taken into account, use <code>CRAWLEE_AVAILABLE_MEMORY_RATIO</code> instead</li><li>some <code>AutoscaledPool</code> options are no longer available:<ul><li><code>cpuSnapshotIntervalSecs</code> and <code>memorySnapshotIntervalSecs</code> has been replaced with top level <code>systemInfoIntervalMillis</code> configuration</li><li><code>maxUsedCpuRatio</code> has been moved to the top level configuration</li></ul></li><li><code>ProxyConfiguration.newUrlFunction</code> can be async. <code>.newUrl()</code> and <code>.newProxyInfo()</code> now return promises.</li><li><code>prepareRequestFunction</code> and <code>postResponseFunction</code> options are removed, use navigation hooks instead</li><li><code>gotoFunction</code> and <code>gotoTimeoutSecs</code> are removed</li><li>removed compatibility fix for old/broken request queues with null <code>Request</code> props</li><li><code>fingerprintsOptions</code> renamed to <code>fingerprintOptions</code> (<code>fingerprints</code> -&gt; <code>fingerprint</code>).</li><li><code>fingerprintOptions</code> now accept <code>useFingerprintCache</code> and <code>fingerprintCacheSize</code> (instead of <code>useFingerprintPerProxyCache</code> and <code>fingerprintPerProxyCacheSize</code>, which are now no longer available). This is because the cached fingerprints are no longer connected to proxy URLs but to sessions.</li></ul><h2 id="232-2022-05-05"><a href="https://github.com/apify/crawlee/compare/v2.3.1...v2.3.2">2.3.2</a> (2022-05-05)</h2><ul><li>fix: use default user agent for playwright with chrome instead of the default &quot;headless UA&quot;</li><li>fix: always hide webdriver of chrome browsers</li></ul><h2 id="231-2022-05-03"><a href="https://github.com/apify/crawlee/compare/v2.3.0...v2.3.1">2.3.1</a> (2022-05-03)</h2><ul><li>fix: <code>utils.apifyClient</code> early instantiation (#1330)</li><li>feat: <code>utils.playwright.injectJQuery()</code> (#1337)</li><li>feat: add <code>keyValueStore</code> option to <code>Statistics</code> class (#1345)</li><li>fix: ensure failed req count is correct when using <code>RequestList</code> (#1347)</li><li>fix: random puppeteer crawler (running in headful mode) failure (#1348)<blockquote><p>This should help with the <code>We either navigate top level or have old version of the navigated frame</code> bug in puppeteer.</p></blockquote></li><li>fix: allow returning falsy values in <code>RequestTransform</code>&#x27;s return type</li></ul><h2 id="230-2022-04-07"><a href="https://github.com/apify/crawlee/compare/v2.2.2...v2.3.0">2.3.0</a> (2022-04-07)</h2><ul><li>feat: accept more social media patterns (#1286)</li><li>feat: add multiple click support to <code>enqueueLinksByClickingElements</code> (#1295)</li><li>feat: instance-scoped &quot;global&quot; configuration (#1315)</li><li>feat: requestList accepts proxyConfiguration for requestsFromUrls (#1317)</li><li>feat: update <code>playwright</code> to v1.20.2</li><li>feat: update <code>puppeteer</code> to v13.5.2<blockquote><p>We noticed that with this version of puppeteer actor run could crash with
<code>We either navigate top level or have old version of the navigated frame</code> error
(puppeteer issue <a href="https://github.com/puppeteer/puppeteer/issues/7050">here</a>).
It should not happen while running the browser in headless mode.
In case you need to run the browser in headful mode (<code>headless: false</code>),
we recommend pinning puppeteer version to <code>10.4.0</code> in actor <code>package.json</code> file.</p></blockquote></li><li>feat: stealth deprecation (#1314)</li><li>feat: allow passing a stream to KeyValueStore.setRecord (#1325)</li><li>fix: use correct apify-client instance for snapshotting (#1308)</li><li>fix: automatically reset <code>RequestQueue</code> state after 5 minutes of inactivity, closes #997</li><li>fix: improve guessing of chrome executable path on windows (#1294)</li><li>fix: prune CPU snapshots locally (#1313)</li><li>fix: improve browser launcher types (#1318)</li></ul><h3 id="0-concurrency-mitigation">0 concurrency mitigation</h3><p>This release should resolve the 0 concurrency bug by automatically resetting the
internal <code>RequestQueue</code> state after 5 minutes of inactivity.</p><p>We now track last activity done on a <code>RequestQueue</code> instance:</p><ul><li>added new request</li><li>started processing a request (added to <code>inProgress</code> cache)</li><li>marked request as handled</li><li>reclaimed request</li></ul><p>If we don&#x27;t detect one of those actions in last 5 minutes, and we have some
requests in the <code>inProgress</code> cache, we try to reset the state. We can override
this limit via <code>CRAWLEE_INTERNAL_TIMEOUT</code> env var.</p><p>This should finally resolve the 0 concurrency bug, as it was always about
stuck requests in the <code>inProgress</code> cache.</p><h2 id="222-2022-02-14"><a href="https://github.com/apify/crawlee/compare/v2.2.1...v2.2.2">2.2.2</a> (2022-02-14)</h2><ul><li>fix: ensure <code>request.headers</code> is set</li><li>fix: lower <code>RequestQueue</code> API timeout to 30 seconds</li><li>improve logging for fetching next request and timeouts</li></ul><h2 id="221-2022-01-03"><a href="https://github.com/apify/crawlee/compare/v2.2.0...v2.2.1">2.2.1</a> (2022-01-03)</h2><ul><li>fix: ignore requests that are no longer in progress (#1258)</li><li>fix: do not use <code>tryCancel()</code> from inside sync callback (#1265)</li><li>fix: revert to puppeteer 10.x (#1276)</li><li>fix: wait when <code>body</code> is not available in <code>infiniteScroll()</code> from Puppeteer utils (#1238)</li><li>fix: expose logger classes on the <code>utils.log</code> instance (#1278)</li></ul><h2 id="220-2021-12-17"><a href="https://github.com/apify/crawlee/compare/v2.1.0...v2.2.0">2.2.0</a> (2021-12-17)</h2><h3 id="proxy-per-page">Proxy per page</h3><p>Up until now, browser crawlers used the same session (and therefore the same proxy) for
all request from a single browser * now get a new proxy for each session. This means
that with incognito pages, each page will get a new proxy, aligning the behaviour with
<code>CheerioCrawler</code>.</p><p>This feature is not enabled by default. To use it, we need to enable <code>useIncognitoPages</code>
flag under <code>launchContext</code>:</p><pre><code class="language-ts">new Apify.Playwright({
    launchContext: {
        useIncognitoPages: true,
    },
    // ...
})
</code></pre><blockquote><p>Note that currently there is a performance overhead for using <code>useIncognitoPages</code>.
Use this flag at your own will.</p></blockquote><p>We are planning to enable this feature by default in SDK v3.0.</p><h3 id="abortable-timeouts">Abortable timeouts</h3><p>Previously when a page function timed out, the task still kept running. This could lead to requests being processed multiple times. In v2.2 we now have abortable timeouts that will cancel the task as
early as possible.</p><h3 id="mitigation-of-zero-concurrency-issue">Mitigation of zero concurrency issue</h3><p>Several new timeouts were added to the task function, which should help mitigate the zero concurrency bug. Namely fetching of next request information and reclaiming failed requests back to the queue
are now executed with a timeout with 3 additional retries before the task fails. The timeout is always at least 300s (5 minutes), or <code>requestHandlerTimeoutSecs</code> if that value is higher.</p><h3 id="full-list-of-changes">Full list of changes</h3><ul><li>fix <code>RequestError: URI malformed</code> in cheerio crawler (#1205)</li><li>only provide Cookie header if cookies are present (#1218)</li><li>handle extra cases for <code>diffCookie</code> (#1217)</li><li>add timeout for task function (#1234)</li><li>implement proxy per page in browser crawlers (#1228)</li><li>add fingerprinting support (#1243)</li><li>implement abortable timeouts (#1245)</li><li>add timeouts with retries to <code>runTaskFunction()</code> (#1250)</li><li>automatically convert google spreadsheet URLs to CSV exports (#1255)</li></ul><h2 id="210-2021-10-07"><a href="https://github.com/apify/crawlee/compare/v2.0.7...v2.1.0">2.1.0</a> (2021-10-07)</h2><ul><li>automatically convert google docs share urls to csv download ones in request list (#1174)</li><li>use puppeteer emulating scrolls instead of <code>window.scrollBy</code> (#1170)</li><li>warn if apify proxy is used in proxyUrls (#1173)</li><li>fix <code>YOUTUBE_REGEX_STRING</code> being too greedy (#1171)</li><li>add <code>purgeLocalStorage</code> utility method (#1187)</li><li>catch errors inside request interceptors (#1188, #1190)</li><li>add support for cgroups v2 (#1177)</li><li>fix incorrect offset in <code>fixUrl</code> function (#1184)</li><li>support channel and user links in YouTube regex (#1178)</li><li>fix: allow passing <code>requestsFromUrl</code> to <code>RequestListOptions</code> in TS (#1191)</li><li>allow passing <code>forceCloud</code> down to the KV store (#1186), closes #752</li><li>merge cookies from session with user provided ones (#1201), closes #1197</li><li>use <code>ApifyClient</code> v2 (full rewrite to TS)</li></ul><h2 id="207-2021-09-08"><a href="https://github.com/apify/crawlee/compare/v2.0.6...v2.0.7">2.0.7</a> (2021-09-08)</h2><ul><li>Fix casting of int/bool environment variables (e.g. <code>APIFY_LOCAL_STORAGE_ENABLE_WAL_MODE</code>), closes #956</li><li>Fix incognito pages and user data dir (#1145)</li><li>Add <code>@ts-ignore</code> comments to imports of optional peer dependencies (#1152)</li><li>Use config instance in <code>sdk.openSessionPool()</code> (#1154)</li><li>Add a breaking callback to <code>infiniteScroll</code> (#1140)</li></ul><h2 id="206-2021-08-27"><a href="https://github.com/apify/crawlee/compare/v2.0.5...v2.0.6">2.0.6</a> (2021-08-27)</h2><ul><li>Fix deprecation messages logged from <code>ProxyConfiguration</code> and <code>CheerioCrawler</code>.</li><li>Update <code>got-scraping</code> to receive multiple improvements.</li></ul><h2 id="205-2021-08-24"><a href="https://github.com/apify/crawlee/compare/v2.0.4...v2.0.5">2.0.5</a> (2021-08-24)</h2><ul><li>Fix error handling in puppeteer crawler</li></ul><h2 id="204-2021-08-23"><a href="https://github.com/apify/crawlee/compare/v2.0.3...v2.0.4">2.0.4</a> (2021-08-23)</h2><ul><li>Use <code>sessionToken</code> with <code>got-scraping</code></li></ul><h2 id="203-2021-08-20"><a href="https://github.com/apify/crawlee/compare/v2.0.2...v2.0.3">2.0.3</a> (2021-08-20)</h2><ul><li><strong>BREAKING IN EDGE CASES</strong> * We removed <code>forceUrlEncoding</code> in <code>requestAsBrowser</code> because we found out that recent versions of the underlying HTTP client <code>got</code> already encode URLs
and <code>forceUrlEncoding</code> could lead to weird behavior. We think of this as fixing a bug, so we&#x27;re not bumping the major version.</li><li>Limit <code>handleRequestTimeoutMillis</code> to max valid value to prevent Node.js fallback to <code>1</code>.</li><li>Use <code>got-scraping@^3.0.1</code></li><li>Disable SSL validation on MITM proxie</li><li>Limit <code>handleRequestTimeoutMillis</code> to max valid value</li></ul><h2 id="202-2021-08-12"><a href="https://github.com/apify/crawlee/compare/v2.0.1...v2.0.2">2.0.2</a> (2021-08-12)</h2><ul><li>Fix serialization issues in <code>CheerioCrawler</code> caused by parser conflicts in recent versions of <code>cheerio</code>.</li></ul><h2 id="201-2021-08-06"><a href="https://github.com/apify/crawlee/compare/v2.0.0...v2.0.1">2.0.1</a> (2021-08-06)</h2><ul><li>Use <code>got-scraping</code> 2.0.1 until fully compatible.</li></ul><h2 id="200-2021-08-05"><a href="https://github.com/apify/crawlee/compare/v1.3.4...v2.0.0">2.0.0</a> (2021-08-05)</h2><ul><li><strong>BREAKING</strong>: Require Node.js &gt;=15.10.0 because HTTP2 support on lower Node.js versions is very buggy.</li><li><strong>BREAKING</strong>: Bump <code>cheerio</code> to <code>1.0.0-rc.10</code> from <code>rc.3</code>. There were breaking changes in <code>cheerio</code> between the versions so this bump might be breaking for you as well.</li><li>Remove <code>LiveViewServer</code> which was deprecated before release of SDK v1.</li></ul></section></div><footer class="tsd-footer">Powered by<!-- --> <a href="https://github.com/milesj/docusaurus-plugin-typedoc-api">docusaurus-plugin-typedoc-api</a> <!-- -->and <a href="https://typedoc.org/">TypeDoc</a></footer></article></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#300-2022-07-13" class="table-of-contents__link toc-highlight">3.0.0 (2022-07-13)</a><ul><li><a href="#crawlee-vs-apify-sdk" class="table-of-contents__link toc-highlight">Crawlee vs Apify SDK</a><ul><li><a href="#installing-crawlee" class="table-of-contents__link toc-highlight">Installing Crawlee</a></li></ul></li><li><a href="#full-typescript-support" class="table-of-contents__link toc-highlight">Full TypeScript support</a><ul><li><a href="#docker-build" class="table-of-contents__link toc-highlight">Docker build</a></li></ul></li><li><a href="#browser-fingerprints" class="table-of-contents__link toc-highlight">Browser fingerprints</a></li><li><a href="#session-cookie-method-renames" class="table-of-contents__link toc-highlight">Session cookie method renames</a></li><li><a href="#memory-storage" class="table-of-contents__link toc-highlight">Memory storage</a></li><li><a href="#purging-of-the-default-storage" class="table-of-contents__link toc-highlight">Purging of the default storage</a></li><li><a href="#renamed-crawler-options-and-interfaces" class="table-of-contents__link toc-highlight">Renamed crawler options and interfaces</a></li><li><a href="#context-aware-helpers" class="table-of-contents__link toc-highlight">Context aware helpers</a><ul><li><a href="#enqueuing-links" class="table-of-contents__link toc-highlight">Enqueuing links</a></li></ul></li><li><a href="#implicit-requestqueue-instance" class="table-of-contents__link toc-highlight">Implicit <code>RequestQueue</code> instance</a></li><li><a href="#crawleraddrequests" class="table-of-contents__link toc-highlight"><code>crawler.addRequests()</code></a></li><li><a href="#less-verbose-error-logging" class="table-of-contents__link toc-highlight">Less verbose error logging</a></li><li><a href="#removal-of-requestasbrowser" class="table-of-contents__link toc-highlight">Removal of <code>requestAsBrowser</code></a><ul><li><a href="#how-to-use-sendrequest" class="table-of-contents__link toc-highlight">How to use <code>sendRequest()</code>?</a></li><li><a href="#removed-options" class="table-of-contents__link toc-highlight">Removed options</a></li><li><a href="#renamed-options" class="table-of-contents__link toc-highlight">Renamed options</a><ul><li><a href="#payload" class="table-of-contents__link toc-highlight"><code>payload</code></a></li><li><a href="#ignoresslerrors" class="table-of-contents__link toc-highlight"><code>ignoreSslErrors</code></a></li><li><a href="#header-generator-options" class="table-of-contents__link toc-highlight"><code>header-generator</code> options</a></li><li><a href="#timeoutsecs" class="table-of-contents__link toc-highlight"><code>timeoutSecs</code></a></li><li><a href="#throwonhttperrors" class="table-of-contents__link toc-highlight"><code>throwOnHttpErrors</code></a></li><li><a href="#decodebody" class="table-of-contents__link toc-highlight"><code>decodeBody</code></a></li><li><a href="#abortfunction" class="table-of-contents__link toc-highlight"><code>abortFunction</code></a></li></ul></li></ul></li><li><a href="#removal-of-browser-pool-plugin-mixing" class="table-of-contents__link toc-highlight">Removal of browser pool plugin mixing</a></li><li><a href="#handling-requests-outside-of-browser" class="table-of-contents__link toc-highlight">Handling requests outside of browser</a></li><li><a href="#logging" class="table-of-contents__link toc-highlight">Logging</a></li><li><a href="#auto-saved-crawler-state" class="table-of-contents__link toc-highlight">Auto-saved crawler state</a></li><li><a href="#apify-sdk" class="table-of-contents__link toc-highlight">Apify SDK</a><ul><li><a href="#events" class="table-of-contents__link toc-highlight">Events</a></li></ul></li><li><a href="#smallerinternal-breaking-changes" class="table-of-contents__link toc-highlight">Smaller/internal breaking changes</a></li></ul></li><li><a href="#232-2022-05-05" class="table-of-contents__link toc-highlight">2.3.2 (2022-05-05)</a></li><li><a href="#231-2022-05-03" class="table-of-contents__link toc-highlight">2.3.1 (2022-05-03)</a></li><li><a href="#230-2022-04-07" class="table-of-contents__link toc-highlight">2.3.0 (2022-04-07)</a><ul><li><a href="#0-concurrency-mitigation" class="table-of-contents__link toc-highlight">0 concurrency mitigation</a></li></ul></li><li><a href="#222-2022-02-14" class="table-of-contents__link toc-highlight">2.2.2 (2022-02-14)</a></li><li><a href="#221-2022-01-03" class="table-of-contents__link toc-highlight">2.2.1 (2022-01-03)</a></li><li><a href="#220-2021-12-17" class="table-of-contents__link toc-highlight">2.2.0 (2021-12-17)</a><ul><li><a href="#proxy-per-page" class="table-of-contents__link toc-highlight">Proxy per page</a></li><li><a href="#abortable-timeouts" class="table-of-contents__link toc-highlight">Abortable timeouts</a></li><li><a href="#mitigation-of-zero-concurrency-issue" class="table-of-contents__link toc-highlight">Mitigation of zero concurrency issue</a></li><li><a href="#full-list-of-changes" class="table-of-contents__link toc-highlight">Full list of changes</a></li></ul></li><li><a href="#210-2021-10-07" class="table-of-contents__link toc-highlight">2.1.0 (2021-10-07)</a></li><li><a href="#207-2021-09-08" class="table-of-contents__link toc-highlight">2.0.7 (2021-09-08)</a></li><li><a href="#206-2021-08-27" class="table-of-contents__link toc-highlight">2.0.6 (2021-08-27)</a></li><li><a href="#205-2021-08-24" class="table-of-contents__link toc-highlight">2.0.5 (2021-08-24)</a></li><li><a href="#204-2021-08-23" class="table-of-contents__link toc-highlight">2.0.4 (2021-08-23)</a></li><li><a href="#203-2021-08-20" class="table-of-contents__link toc-highlight">2.0.3 (2021-08-20)</a></li><li><a href="#202-2021-08-12" class="table-of-contents__link toc-highlight">2.0.2 (2021-08-12)</a></li><li><a href="#201-2021-08-06" class="table-of-contents__link toc-highlight">2.0.1 (2021-08-06)</a></li><li><a href="#200-2021-08-05" class="table-of-contents__link toc-highlight">2.0.0 (2021-08-05)</a></li></ul></div></div></div></div></main></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/guides">Guides</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/examples">Examples</a></li><li class="footer__item"><a class="footer__link-item" href="/api/core">API reference</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://discord.com/invite/jyEM2PRvMU" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/crawlee" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/apify" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.facebook.com/apifytech" target="_blank" rel="noopener noreferrer" class="footer__link-item">Facebook<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://apify.com" target="_blank" class="footer__link-item">
        <span>
            Apify Platform
            <svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" style="margin-left: 0.3rem; position: relative; top: 1px;">
                <path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z">
                </path>
            </svg>
        </span>
    </a></li><li class="footer__item"><a href="https://docusaurus.io" target="_blank" class="footer__link-item">
        <span>
            Docusaurus
            <svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" style="margin-left: 0.3rem; position: relative; top: 1px;">
                <path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z">
                </path>
            </svg>
        </span>
    </a></li><li class="footer__item"><a href="https://github.com/apify/crawlee" target="_blank" class="footer__link-item">
        <span>
            GitHub
            <svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" style="margin-left: 0.3rem; position: relative; top: 1px;">
                <path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z">
                </path>
            </svg>
        </span>
    </a></li></ul></div></div><div class="footer__bottom text--center"><div class="margin-bottom--sm"><a class="footerLogoLink_BH7S" href="/"><img src="/img/apify_logo.svg" class="themedImage_ToTc themedImage--light_HNdA footer__logo" width="60px" height="60px"><img src="/img/apify_logo.svg" class="themedImage_ToTc themedImage--dark_i4oU footer__logo" width="60px" height="60px"></a></div><div class="footer__copyright">Copyright © 2022 Apify Technologies s.r.o.</div></div></div></footer></div></div>
<script src="/assets/js/runtime~main.9bda2722.js"></script>
<script src="/assets/js/main.3e40fcfa.js"></script>
</body>
</html>